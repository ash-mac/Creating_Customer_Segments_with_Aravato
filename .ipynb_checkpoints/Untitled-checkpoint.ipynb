{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Perform feature trimming, re-encoding, and engineering for demographics\n",
    "    data\n",
    "    \n",
    "    INPUT: Demographics DataFrame\n",
    "    OUTPUT: Trimmed and cleaned demographics DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put in code here to execute all main cleaning steps:\n",
    "    # convert missing value codes into NaNs, ...\n",
    "    \n",
    "    for i,columns in enumerate(col_names):\n",
    "        df[columns] = df[columns].replace(feat_info.iloc[i,3],np.nan)\n",
    "        \n",
    "        \n",
    "    # remove selected columns and rows, ...\n",
    "    \n",
    "    nan_col_count = []\n",
    "    for column in col_names:\n",
    "        nan_col_count.append(df[column].isna().sum())\n",
    "    too_many_missing_col = []\n",
    "    for i in range(85):\n",
    "        if(nan_col_count[i] > 300000):\n",
    "            too_many_missing_col.append(i)\n",
    "    df1 = df.drop(df.columns[too_many_missing_col],axis = 1)\n",
    "    feat_info1 = feat_info.drop(feat_info.index[too_many_missing_col],axis = 0)\n",
    "    nan_row_count = list(df1.isnull().sum(axis=1))\n",
    "    too_many_missing_row = []\n",
    "    for i in range(len(nan_row_count)):\n",
    "        if(nan_row_count[i] >= 29):\n",
    "            too_many_missing_row.append(i)\n",
    "    df2 = df1.drop(df1.index[too_many_missing_row],axis = 0)\n",
    "    df_dropped_rows = df1.loc[too_many_missing_row]\n",
    "    \n",
    "    \n",
    "    # select, re-encode, and engineer column values.\n",
    "    \n",
    "    less_missing = []\n",
    "    for i in range(85):\n",
    "        if i not in too_many_missing_col:\n",
    "            less_missing.append(i)\n",
    "    # storing nan_counts of undropped columns and sorting them to get the columns with least missing values\n",
    "    less_nan_col_count = []\n",
    "    for i in range(len(less_missing)):\n",
    "        less_nan_col_count.append((nan_col_count[less_missing[i]],less_missing[i]))\n",
    "    less_nan_col_count.sort()\n",
    "    binary = []\n",
    "    cat_feat_col_wise = []\n",
    "    many_cats = []\n",
    "    for i in cat_feat:\n",
    "        arr = df.iloc[:,i].unique()\n",
    "        arr = [x for x in arr if str(x) != 'nan']\n",
    "        arr.sort()\n",
    "        if(len(arr) == 2):\n",
    "            binary.append([i,arr])\n",
    "        elif(len(arr)<=6):\n",
    "            cat_feat_col_wise.append([i,arr,len(arr)])\n",
    "        elif(len(arr)>6):\n",
    "            many_cats.append(i)\n",
    "    df_encoded = df2\n",
    "    for bin_feat in binary:\n",
    "        if bin_feat[0] not in too_many_missing_col:\n",
    "            df_encoded[col_names[bin_feat[0]]].replace({bin_feat[1][0]:0,bin_feat[1][1]:1},inplace = True)\n",
    "    col_cats = []\n",
    "    for i in range(len(cat_feat_col_wise)):\n",
    "        col_cats.append(col_names[cat_feat_col_wise[i][0]])\n",
    "    already_dropped_many_cats_local = set.intersection(set(col_names[many_cats]),set(col_names[too_many_missing_col]))\n",
    "    already_dropped_col_cats_local = set.intersection(set(col_cats),set(col_names[too_many_missing_col]))\n",
    "    for category in already_dropped_col_cats:\n",
    "        col_cats.remove(category)\n",
    "    for category in already_dropped_many_cats:\n",
    "        many_cats.remove(category)\n",
    "    df_encoded = df_encoded.drop(col_names[many_cats],axis = 1)\n",
    "    df_encoded = pd.get_dummies(df_encoded,columns = col_cats)\n",
    "    df_encoded['generation'] = df_encoded['PRAEGENDE_JUGENDJAHRE'].apply(encode_gen)\n",
    "    df_encoded['movement'] = df_encoded['PRAEGENDE_JUGENDJAHRE'].apply(encode_move)\n",
    "    df_encoded = df_encoded.drop(['PRAEGENDE_JUGENDJAHRE'],axis = 1)\n",
    "    df_encoded['wealth'] = df_encoded['CAMEO_INTL_2015'].apply(encode_wealth)\n",
    "    df_encoded['life_stage'] = df_encoded['CAMEO_INTL_2015'].apply(encode_life)\n",
    "    df_encoded = df_encoded.drop(['CAMEO_INTL_2015'],axis = 1)\n",
    "    other_mixed = []\n",
    "    for feat in feat_info1.index:\n",
    "        if(col_names[feat] in df_encoded.columns and feat_info1.loc[feat,'type'] == 'mixed'):\n",
    "            other_mixed.append(col_names[feat])\n",
    "    df_encoded = df_encoded.drop(other_mixed,axis = 1)\n",
    "    \n",
    "    \n",
    "    # Return the cleaned dataframe.\n",
    "    \n",
    "    return df_encoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
